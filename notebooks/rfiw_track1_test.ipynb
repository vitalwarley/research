{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gc\n",
    "import torch\n",
    "from keras.preprocessing import image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.chdir('../rfiw2021')\n",
    "\n",
    "from Track1.models import Net\n",
    "from Track1.utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = 'Track1'\n",
    "SAMPLE = 'Track1/sample0/' # Path to sample image\n",
    "MODEL_PATH = '../notebooks/data/model_track1.pth'\n",
    "THRESHOLD = 0.11546290665864944 # Classification threshold\n",
    "BATCH_SIZE = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating res object to keep the accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['bb', 'ss', 'sibs', 'fd', 'md', 'fs', 'ms', 'gfgd', 'gmgd', 'gfgs', 'gmgs', 'avg']\n",
    "res = {}\n",
    "for n in classes:\n",
    "    res[n]=[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().cuda()\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the test database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_path = os.path.join(SAMPLE,\"test.txt\")\n",
    "test_samples=[]\n",
    "f = open(test_file_path, \"r+\", encoding='utf-8')\n",
    "while True:\n",
    "    line=f.readline().replace('\\n','')\n",
    "    if not line:\n",
    "        break\n",
    "    else:\n",
    "        test_samples.append(line.split(' '))\n",
    "f.close()\n",
    "res['avg'][0]=len(test_samples)\n",
    "for now in test_samples:\n",
    "    res[now[3]][0]+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    img = image.load_img(f\"{FILE}/{path}\", target_size=(112, 112))\n",
    "    img = np.array(img).astype(float)\n",
    "    return np.transpose(img, (2, 0, 1))\n",
    "\n",
    "def gen(list_tuples, batch_size):\n",
    "    total=len(list_tuples)\n",
    "    start=0\n",
    "    while True:\n",
    "        if start+batch_size<total:\n",
    "            end=start+batch_size\n",
    "        else:\n",
    "            end=total\n",
    "        batch_list=list_tuples[start:end]\n",
    "        datas=[]\n",
    "        labels=[]\n",
    "        classes=[]\n",
    "        for now in batch_list:\n",
    "            datas.append([now[1],now[2]])\n",
    "            labels.append(int(now[4]))\n",
    "            classes.append(now[3])\n",
    "        X1 = np.array([read_image(x[0]) for x in datas])\n",
    "        X2 = np.array([read_image(x[1]) for x in datas])\n",
    "        yield X1, X2, labels,classes,batch_list\n",
    "        start=end\n",
    "        if start == total:\n",
    "            yield None,None,None,None,None\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "994it [08:31,  1.94it/s]                         \n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for img1, img2, labels, classes, batch_list in tqdm(gen(test_samples, BATCH_SIZE), total=len(test_samples) // BATCH_SIZE):\n",
    "        if img1 is not None:\n",
    "            img1 = torch.from_numpy(img1).type(torch.float).cuda()\n",
    "            img2 = torch.from_numpy(img2).type(torch.float).cuda()\n",
    "            em1, em2, _, _ = model([img1, img2])\n",
    "            pred = torch.cosine_similarity(em1, em2, dim=1).cpu().detach().numpy().tolist()\n",
    "            for i in range(len(pred)):\n",
    "                if pred[i] >= THRESHOLD:\n",
    "                    p = 1\n",
    "                else:\n",
    "                    p = 0\n",
    "                if p == labels[i]:\n",
    "                    res['avg'][1] += 1\n",
    "                    res[classes[i]][1] += 1\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the results in a log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bb : 0.8107118644067797\n",
      "ss : 0.8119018618409605\n",
      "sibs : 0.786174575278266\n",
      "fd : 0.7393098893841836\n",
      "md : 0.7911679068262698\n",
      "fs : 0.8233587786259542\n",
      "ms : 0.7614752455401884\n",
      "gfgd : 0.7742663656884876\n",
      "gmgd : 0.7509293680297398\n",
      "gfgs : 0.7224489795918367\n",
      "gmgs : 0.6033519553072626\n",
      "avg : 0.7895226832398158\n"
     ]
    }
   ],
   "source": [
    "for key in res:\n",
    "    mylog(key, ':', res[key][1] / res[key][0], path='testando')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
