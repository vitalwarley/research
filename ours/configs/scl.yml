seed_everything: 100
ckpt_path: null
trainer:
  limit_train_batches: 50
  accumulate_grad_batches: 1
  num_sanity_val_steps: 1
  log_every_n_steps: 10
  accelerator: "gpu"
  deterministic: yes
  fast_dev_run: no
  max_epochs: 40
  default_root_dir: exp/
  callbacks:
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        dirpath: exp/checkpoints/
        filename: '{epoch}-{loss/val:.3f}-{loss/train:.3f}-{auc:.6f}'
        monitor: auc
        verbose: no
        save_last: yes
        save_top_k: 1
        save_weights_only: no
        auto_insert_metric_name: no
        mode: max
    - class_path: lightning.pytorch.callbacks.EarlyStopping
      init_args:
        monitor: 'auc'  # Replace 'auc' with your chosen metric
        patience: 5  # Number of epochs to wait for improvement
        verbose: False
        mode: 'max'  # Use 'min' if the metric should decrease

data:
   class_path: datasets.sclff.SCLFFDataModule
   init_args:
     batch_size: 20
     root_dir: data/facornet
     sampler: no
     augment: False
     bias: yes
     dataset: facornet
     augmentation_params:
       color_jitter:
         brightness: 0.5
         contrast: 0.5
         saturation: 0.5
         hue: 0.1
       random_grayscale_prob: 0.2
       random_horizontal_flip_prob: 0.5

model:
  class_path: models.scl.SCL
  init_args:
    num_families: 0
    loss_factor: 0
    optimizer: SGD
    adamw_beta1: 0.9
    adamw_beta2: 0.999
    lr: 1e-4
    momentum: 0.9
    weight_decay: 0
    start_lr: 1e-10
    end_lr: 1e-10
    lr_factor: 0.75
    lr_steps: [8, 14, 25, 35, 40, 50, 60]
    warmup: 200
    cooldown: 400
    scheduler: null
    threshold: null
    anneal_strategy: cos
    weights: null
    model:
      class_path: models.base.SimpleModel
      init_args:
        model: adaface_ir_101
    loss: 
      class_path: losses.scl.HardContrastiveLossV6
      init_args:
        tau: 0.2
        alpha: 0.8
        gamma_ex: 0.0
        gamma_in: 0.0
        dim_mixing: no
