{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36a63343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0824a4d9-7852-4b39-9662-38f507a49145",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "559892f9-0b14-4e06-b5e6-c1bc19da6882",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5938882a-02ae-445b-9311-fabc81ee2fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from sklearn.manifold import TSNE\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b23bc8c2-40a1-42d2-abf5-27314271d0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scienceplots\n",
    "\n",
    "plt.style.use([\"science\", \"ieee\", \"grid\", \"no-latex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb64f707-3b4a-4640-a800-68a535582df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    IS_NOTEBOOK = True\n",
    "    HERE = Path(__file__).resolve().parent\n",
    "except NameError:\n",
    "    IS_NOTEBOOK = False\n",
    "    HERE = Path().resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ded135d-b083-46bd-a170-b72593dc9584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/warley/dev/research/kinship/notebooks\n"
     ]
    }
   ],
   "source": [
    "print(HERE)\n",
    "sys.path.insert(0, str(Path(HERE, \"..\")))  # kinship root sys.path.insert(0, str(Path(HERE, \"..\")))  # kinship root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d74b5b4-2e1f-420b-8da8-fe744897a453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/warley/dev/research/kinship/notebooks/..', '/usr/lib/python311.zip', '/usr/lib/python3.11', '/usr/lib/python3.11/lib-dynload', '', '/home/warley/.virtualenvs/research/lib/python3.11/site-packages']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5759470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import FIW  # noqa: E402\n",
    "from ours.models.base import SimpleModel  # noqa: E402\n",
    "from models.facornet import FaCoRV0, FaCoRNetLightning\n",
    "from models.attention import FaCoRAttention\n",
    "from ours.models.scl import SCL  # noqa: E402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dc6e8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(val_loader, model):\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "\n",
    "    for img, family_id in tqdm(val_loader):\n",
    "        with torch.no_grad():\n",
    "            embedding, _ = model(img.cuda())\n",
    "            embedding = embedding.cpu().numpy()\n",
    "            embedding = normalize(embedding)\n",
    "            embeddings.append(embedding)\n",
    "            labels.append(family_id)\n",
    "\n",
    "    # Now, embeddings contain all the embeddings from your model\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    labels = np.concatenate(labels)\n",
    "\n",
    "    return embeddings, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b06de29f-2e4a-482a-adf6-10f8f429b03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 0.9922778767136677), ('B', 0.6)] [('A', 0.9922778767136677), ('B', 0.6)]\n",
      "['A', 'B']\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    \"\"\"Compute the cosine similarity between two vectors.\"\"\"\n",
    "    return 1 - cosine(a, b)\n",
    "\n",
    "\n",
    "def rank_top_families(embeddings, family_ids, n=5):\n",
    "    \"\"\"Rank the top 5 families by highest pairwise mean similarity.\n",
    "\n",
    "    Args:\n",
    "        embeddings (np.ndarray): 2D array of shape (n_samples, n_features).\n",
    "        family_ids (list): List of family IDs corresponding to each embedding.\n",
    "\n",
    "    Returns:\n",
    "        list: Top 5 family IDs ranked by mean similarity.\n",
    "    \"\"\"\n",
    "    family_similarity = defaultdict(list)\n",
    "\n",
    "    # Group embeddings by family\n",
    "    family_groups = defaultdict(list)\n",
    "    for emb, fam_id in zip(embeddings, family_ids):\n",
    "        family_groups[fam_id].append(emb)\n",
    "\n",
    "    # Calculate pairwise similarities within each family\n",
    "    for fam_id, emb_group in family_groups.items():\n",
    "        num_embeddings = len(emb_group)\n",
    "        if num_embeddings < 2:\n",
    "            continue  # Skip families with less than 2 embeddings\n",
    "\n",
    "        total_similarity = 0\n",
    "        count = 0\n",
    "\n",
    "        for i in range(num_embeddings):\n",
    "            for j in range(i + 1, num_embeddings):\n",
    "                sim = cosine_similarity(emb_group[i], emb_group[j])\n",
    "                total_similarity += sim\n",
    "                count += 1\n",
    "\n",
    "        mean_similarity = total_similarity / count if count > 0 else 0\n",
    "        family_similarity[fam_id] = mean_similarity\n",
    "\n",
    "    # Sort families by mean similarity\n",
    "    sorted_families = sorted(family_similarity.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(sorted_families[:n], sorted_families[-n:])\n",
    "\n",
    "    # Get top 5 families\n",
    "    top_five_families = [fam_id for fam_id, _ in sorted_families]\n",
    "    # Calculate the step size\n",
    "    num_samples = len(top_five_families)\n",
    "    step = len(top_five_families) // num_samples\n",
    "\n",
    "    # Select samples\n",
    "    samples = [top_five_families[i * step] for i in range(num_samples)]\n",
    "\n",
    "    return samples\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "embeddings = np.array([[1, 2], [2, 3], [3, 4], [1, 0], [2, 1]])\n",
    "family_ids = [\"A\", \"A\", \"B\", \"B\", \"C\"]\n",
    "print(rank_top_families(embeddings, family_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "633c5cd9-8aa9-4597-a031-3fe71934bd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 0.0), ('B', 0.0)] [('A', 0.0), ('B', 0.0)]\n",
      "['A', 'B']\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    \"\"\"Compute the cosine similarity between two vectors.\"\"\"\n",
    "    return 1 - cosine(a, b)\n",
    "\n",
    "\n",
    "def rank_top_clustered_families(embeddings, family_ids, n=5):\n",
    "    \"\"\"Rank families by lowest variance in pairwise distances.\n",
    "\n",
    "    Args:\n",
    "        embeddings (np.ndarray): 2D array of shape (n_samples, n_features).\n",
    "        family_ids (list): List of family IDs corresponding to each embedding.\n",
    "        n (int): Number of families to return.\n",
    "\n",
    "    Returns:\n",
    "        list: Top N family IDs ranked by lowest variance in pairwise distances.\n",
    "    \"\"\"\n",
    "    family_variance = defaultdict(list)\n",
    "\n",
    "    # Group embeddings by family\n",
    "    family_groups = defaultdict(list)\n",
    "    for emb, fam_id in zip(embeddings, family_ids):\n",
    "        family_groups[fam_id].append(emb)\n",
    "\n",
    "    # Calculate pairwise distances within each family\n",
    "    for fam_id, emb_group in family_groups.items():\n",
    "        num_embeddings = len(emb_group)\n",
    "        if num_embeddings < 2:\n",
    "            continue  # Skip families with less than 2 embeddings\n",
    "\n",
    "        # Calculate pairwise distances using cosine distance\n",
    "        distance_matrix = squareform(pdist(emb_group, metric=\"cosine\"))\n",
    "\n",
    "        # Flatten the distance matrix and compute variance\n",
    "        distances = distance_matrix[np.triu_indices(num_embeddings, k=1)]\n",
    "        variance = np.var(distances) if distances.size > 0 else 0\n",
    "        family_variance[fam_id] = variance\n",
    "\n",
    "    # Sort families by variance (lower is better)\n",
    "    sorted_families = sorted(family_variance.items(), key=lambda x: x[1])\n",
    "    print(sorted_families[:n], sorted_families[-n:])\n",
    "\n",
    "    # Get top N families\n",
    "    top_n_families = [fam_id for fam_id, _ in sorted_families[:n]]\n",
    "\n",
    "    return top_n_families\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "embeddings = np.array([[1, 2], [2, 3], [3, 4], [1, 0], [2, 1]])\n",
    "family_ids = [\"A\", \"A\", \"B\", \"B\", \"C\"]\n",
    "print(rank_top_clustered_families(embeddings, family_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd88893b-26ad-40fb-b2ef-111ec681cef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'A', 'B']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "\n",
    "def compute_centroids(embeddings, family_ids):\n",
    "    \"\"\"Compute the centroid for each family group.\n",
    "\n",
    "    Args:\n",
    "        embeddings (np.ndarray): 2D array of shape (n_samples, n_features).\n",
    "        family_ids (list): List of family IDs corresponding to each embedding.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping family IDs to their centroids.\n",
    "    \"\"\"\n",
    "    family_groups = defaultdict(list)\n",
    "\n",
    "    # Group embeddings by family\n",
    "    for emb, fam_id in zip(embeddings, family_ids):\n",
    "        family_groups[fam_id].append(emb)\n",
    "\n",
    "    # Calculate centroids\n",
    "    centroids = {}\n",
    "    for fam_id, emb_group in family_groups.items():\n",
    "        centroids[fam_id] = np.mean(emb_group, axis=0)\n",
    "\n",
    "    return centroids\n",
    "\n",
    "\n",
    "def select_most_distant_families(embeddings, family_ids, n=5):\n",
    "    \"\"\"Select a random family and the n-1 most distant families based on centroid distances.\n",
    "\n",
    "    Args:\n",
    "        embeddings (np.ndarray): 2D array of shape (n_samples, n_features).\n",
    "        family_ids (list): List of family IDs corresponding to each embedding.\n",
    "        n (int): Total number of families to select (1 random family + n-1 distant).\n",
    "\n",
    "    Returns:\n",
    "        list: A list of family IDs including the random family and the most distant families.\n",
    "    \"\"\"\n",
    "    # Compute centroids\n",
    "    centroids = compute_centroids(embeddings, family_ids)\n",
    "\n",
    "    # Select a random family\n",
    "    random_family = random.choice(list(centroids.keys()))\n",
    "\n",
    "    # Calculate distances from the centroid of the selected random family to all other centroids\n",
    "    distances = {}\n",
    "    random_centroid = centroids[random_family]\n",
    "\n",
    "    for fam_id, centroid in centroids.items():\n",
    "        if fam_id != random_family:  # Exclude the random family itself\n",
    "            distances[fam_id] = euclidean(random_centroid, centroid)\n",
    "\n",
    "    # Sort families by distance (descending) and select the top n-1\n",
    "    most_distant_families = sorted(distances.items(), key=lambda x: x[1], reverse=True)[: n - 1]\n",
    "\n",
    "    # Return the random family and its most distant families\n",
    "    selected_families = [random_family] + [fam_id for fam_id, _ in most_distant_families]\n",
    "\n",
    "    return selected_families\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "embeddings = np.array([[1, 2], [2, 3], [3, 4], [1, 0], [2, 1]])\n",
    "family_ids = [\"A\", \"A\", \"B\", \"B\", \"C\"]\n",
    "print(select_most_distant_families(embeddings, family_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82ae803b-b835-4c4a-9a20-24b5ec3a2f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_sequentially_distant_families(embeddings, family_ids, n=5):\n",
    "    \"\"\"Select a random family and the n-1 most distant families based on sequential distances.\n",
    "\n",
    "    Args:\n",
    "        embeddings (np.ndarray): 2D array of shape (n_samples, n_features).\n",
    "        family_ids (list): List of family IDs corresponding to each embedding.\n",
    "        n (int): Total number of families to select (1 random family + n-1 distant).\n",
    "\n",
    "    Returns:\n",
    "        list: A list of family IDs including the random family and the most distant families.\n",
    "    \"\"\"\n",
    "    # Compute centroids\n",
    "    centroids = compute_centroids(embeddings, family_ids)\n",
    "\n",
    "    # Select a random family\n",
    "    selected_families = []\n",
    "    random_family = random.choice(list(centroids.keys()))\n",
    "    selected_families.append(random_family)\n",
    "\n",
    "    # Start with the random centroid\n",
    "    current_centroid = centroids[random_family]\n",
    "\n",
    "    for _ in range(1, n):\n",
    "        # Calculate distances from the current centroid to all other centroids\n",
    "        distances = {}\n",
    "\n",
    "        for fam_id, centroid in centroids.items():\n",
    "            if fam_id not in selected_families:  # Exclude already selected families\n",
    "                distances[fam_id] = euclidean(current_centroid, centroid)\n",
    "\n",
    "        # Find the most distant family\n",
    "        most_distant_family = max(distances, key=distances.get)\n",
    "        selected_families.append(most_distant_family)\n",
    "\n",
    "        # Update the current centroid\n",
    "        current_centroid = centroids[most_distant_family]\n",
    "\n",
    "    return selected_families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe94e531-9aae-4ec7-9be1-97896e572193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/warley/.virtualenvs/research/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def plot_embeddings(embeddings, labels, plot_path):\n",
    "    # Set up perplexity values\n",
    "    n_embeddings = len(embeddings)\n",
    "    perplexities = [10, 30, 50]\n",
    "\n",
    "    # Create a color map for families\n",
    "    family_ids = rank_top_families(embeddings, labels, n=5)\n",
    "    colors = [\"red\", \"blue\", \"green\", \"purple\", \"orange\"]\n",
    "    color_map = dict(list(zip(family_ids, colors)))\n",
    "\n",
    "    # Define n_subplots based on number of perplexity values\n",
    "    n_subplots = len(perplexities) + 1  # +1 for UMAP\n",
    "    n_col = 2\n",
    "    n_row = int(np.ceil(n_subplots / n_col))\n",
    "\n",
    "    # Prepare a figure to hold the subplots\n",
    "    fig, axes = plt.subplots(n_row, n_col, figsize=(15, 5 * n_row))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Generate and plot t-SNE for different perplexity values\n",
    "    for i, perplexity in enumerate(perplexities):\n",
    "        print(f\"Generating t-SNE with perplexity={perplexity}\")\n",
    "        tsne = TSNE(n_components=2, perplexity=perplexity, random_state=100, n_iter=2000, metric=\"cosine\", init=\"pca\")\n",
    "        embeddings_2d = tsne.fit_transform(embeddings)\n",
    "\n",
    "        ax = axes[i]  # Get the current subplot\n",
    "\n",
    "        # Plot\n",
    "        for label, color in color_map.items():\n",
    "            idxs = [idx for idx, val in enumerate(labels) if val == str(label)]\n",
    "            ax.scatter(embeddings_2d[idxs, 0], embeddings_2d[idxs, 1], color=color, label=f\"Family #0{label}\")\n",
    "\n",
    "        ax.set_title(f\"t-SNE Perplexity: {perplexity}\")\n",
    "        ax.legend()\n",
    "\n",
    "    # Generate and plot UMAP\n",
    "    print(\"Generating UMAP...\")\n",
    "    umap_model = umap.UMAP(n_components=2, random_state=100, metric=\"cosine\", n_neighbors=10)\n",
    "    embeddings_umap = umap_model.fit_transform(embeddings)\n",
    "\n",
    "    ax = axes[n_subplots - 1]  # Last subplot for UMAP\n",
    "    for label, color in color_map.items():\n",
    "        idxs = [idx for idx, val in enumerate(labels) if val == str(label)]\n",
    "        ax.scatter(embeddings_umap[idxs, 0], embeddings_umap[idxs, 1], color=color, label=f\"Family #0{label}\")\n",
    "\n",
    "    ax.set_title(\"UMAP\")\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if plot_path:\n",
    "        Path(plot_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "        plt.savefig(plot_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb229440-fc2c-4c78-b2b5-ac14cae34683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(root_dir, ckpt_path, batch_size, samples_per_member, gpu: int = 0):\n",
    "    # Loading and sampling the dataset\n",
    "    val_dataset = FIW(root_dir=root_dir, families=[250, 283, 409, 735, 873], samples_per_member=samples_per_member)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, pin_memory=False)\n",
    "\n",
    "    # Loading model\n",
    "    checkpoint = torch.load(ckpt_path)\n",
    "    # simple_model = SimpleModel('adaface_ir_101')\n",
    "    # model = SCL(model=simple_model, loss=None)\n",
    "    facor = FaCoRV0()\n",
    "    model = FaCoRNetLightning(model=facor, loss=None)\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    model = model.model.backbone\n",
    "    model.eval()\n",
    "    model.cuda()\n",
    "\n",
    "    torch.manual_seed(100)\n",
    "\n",
    "    return model, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76cb316a-e772-465e-b1d8-d726f10f2a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, val_loader, plot_path: str = \"\"):\n",
    "    # Extracting embeddings\n",
    "    embeddings, labels = extract_embeddings(val_loader, model)\n",
    "\n",
    "    # Plotting\n",
    "    plot_embeddings(embeddings, labels, plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "000476e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser():\n",
    "    parser = argparse.ArgumentParser(description=\"plot embeddings\")\n",
    "    parser.add_argument(\"--root_dir\", type=str, help=\"root directory of dataset\")\n",
    "    parser.add_argument(\"--ckpt_path\", type=str, help=\"model save path\")\n",
    "    parser.add_argument(\"--plot_path\", type=str, help=\"plot save path\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=40, help=\"batch size default 40\")\n",
    "    parser.add_argument(\"--gpu\", default=\"0\", type=str, help=\"gpu id you use\")\n",
    "    args = parser.parse_args()\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adffb3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 571/571 [00:00<00:00, 3693.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 7553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189/189 [00:22<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('F0322', 0.9769186059823581), ('F0527', 0.9676497006194555), ('F0437', 0.965483737881787), ('F0781', 0.9644941845079426), ('F0639', 0.9637137468040022)] [('F0489', 0.8147675583892501), ('F0678', 0.8134191506429127), ('F0889', 0.8133681776741664), ('F0695', 0.8077920425719385), ('F0011', 0.8067183943710858)]\n",
      "Generating t-SNE with perplexity=10\n",
      "Generating t-SNE with perplexity=30\n",
      "Generating t-SNE with perplexity=50\n",
      "Generating UMAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/warley/.virtualenvs/research/lib/python3.11/site-packages/umap/umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n",
      "/tmp/ipykernel_126866/416068045.py:59: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "if IS_NOTEBOOK:\n",
    "    if __name__ == \"__main__\":\n",
    "        args = parser()\n",
    "        run(**vars(args))\n",
    "else:\n",
    "    root_dir = Path(HERE, \"../datasets/facornet/images/Validation_A/val-faces\")\n",
    "    batch_size = 40\n",
    "    experiment = \"686449944e814f7fab46150a63f521f4\"\n",
    "    checkpoint = \"25-4.909-1.047-0.873813.ckpt\"\n",
    "    ckpt_path = Path(Path.home(), f\".guild/runs/{experiment}/exp/checkpoints/{checkpoint}\")\n",
    "    plot_path = \"plots_experiments/sota_tsne.png\"\n",
    "    model, val_loader = setup(root_dir, ckpt_path, batch_size, samples_per_member=3)\n",
    "    run(model, val_loader, plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0983d2-368c-4fdc-8207-a0d911aa8aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af23170a-3df9-4151-bb61-46db93f44f51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
